{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"300\" alt=\"cognitiveclass.ai logo\">\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Credit Card Fraud Detection using Scikit-Learn and Snap ML**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **30** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise session you will consolidate your machine learning (ML) modeling skills by using two popular classification models to recognize fraudulent credit card transactions. These models are: Decision Tree and Support Vector Machine. You will use a real dataset to train each of these models. The dataset includes information about \n",
    "transactions made by credit cards in September 2013 by European cardholders. You will use the trained model to assess if a credit card transaction is legitimate or not.\n",
    "\n",
    "In the current exercise session, you will practice not only the Scikit-Learn Python interface, but also the Python API offered by the Snap Machine Learning (Snap ML) library. Snap ML is a high-performance IBM library for ML modeling. It provides highly-efficient CPU/GPU implementations of linear models and tree-based models. Snap ML not only accelerates ML algorithms through system awareness, but it also offers novel ML algorithms with best-in-class accuracy. For more information, please visit [snapml](https://ibm.biz/BdPfxy?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork1047-2022-01-01) information page.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After completing this lab you will be able to:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Perform basic data preprocessing in Python\n",
    "* Model a classification task using the Scikit-Learn and Snap ML Python APIs\n",
    "* Train Suppport Vector Machine and Decision Tree models using Scikit-Learn and Snap ML\n",
    "* Run inference and assess the quality of the trained models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 10px\">\n",
    "    <ol>\n",
    "        <li><a href=\"#introduction\">Introduction</a></li>\n",
    "        <li><a href=\"#import_libraries\">Import Libraries</a></li>\n",
    "        <li><a href=\"#dataset_analysis\">Dataset Analysis</a></li>\n",
    "        <li><a href=\"#dataset_preprocessing\">Dataset Preprocessing</a></li>\n",
    "        <li><a href=\"#dataset_split\">Dataset Train/Test Split</a></li>\n",
    "        <li><a href=\"#dt_sklearn\">Build a Decision Tree Classifier model with Scikit-Learn</a></li>\n",
    "        <li><a href=\"#dt_snap\">Build a Decision Tree Classifier model with Snap ML</a></li>\n",
    "        <li><a href=\"#dt_sklearn_snap\">Evaluate the Scikit-Learn and Snap ML Decision Tree Classifiers</a></li>\n",
    "        <li><a href=\"#svm_sklearn\">Build a Support Vector Machine model with Scikit-Learn</a></li>\n",
    "        <li><a href=\"#svm_snap\">Build a Support Vector Machine model with Snap ML</a></li>\n",
    "        <li><a href=\"#svm_sklearn_snap\">Evaluate the Scikit-Learn and Snap ML Support Vector Machine Models</a></li>\n",
    "    </ol>\n",
    "</div>\n",
    "<br>\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"Introduction\">\n",
    "    <h2>Introduction</h2>\n",
    "    <br>Imagine that you work for a financial institution and part of your job is to build a model that predicts if a credit card transaction is fraudulent or not. You can model the problem as a binary classification problem. A transaction belongs to the positive class (1) if it is a fraud, otherwise it belongs to the negative class (0).\n",
    "    <br>\n",
    "    <br>You have access to transactions that occured over a certain period of time. The majority of the transactions are normally legitimate and only a small fraction are non-legitimate. Thus, typically you have access to a dataset that is highly unbalanced. This is also the case of the current dataset: only 492 transactions out of 284,807 are fraudulent (the positive class - the frauds - accounts for 0.172% of all transactions).\n",
    "    <br>\n",
    "    <br>To train the model you can use part of the input dataset and the remaining data can be used to assess the quality of the trained model. First, let's download the dataset.\n",
    "    <br>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opendatasets in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (0.1.22)\n",
      "Requirement already satisfied: tqdm in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from opendatasets) (4.60.0)\n",
      "Requirement already satisfied: kaggle in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from opendatasets) (1.5.16)\n",
      "Requirement already satisfied: click in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from opendatasets) (8.1.3)\n",
      "Requirement already satisfied: importlib-metadata in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from click->opendatasets) (4.11.4)\n",
      "Requirement already satisfied: six>=1.10 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from kaggle->opendatasets) (1.16.0)\n",
      "Requirement already satisfied: certifi in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from kaggle->opendatasets) (2023.5.7)\n",
      "Requirement already satisfied: python-dateutil in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from kaggle->opendatasets) (2.8.2)\n",
      "Requirement already satisfied: requests in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from kaggle->opendatasets) (2.29.0)\n",
      "Requirement already satisfied: python-slugify in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from kaggle->opendatasets) (8.0.1)\n",
      "Requirement already satisfied: urllib3 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from kaggle->opendatasets) (1.26.15)\n",
      "Requirement already satisfied: bleach in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from kaggle->opendatasets) (6.0.0)\n",
      "Requirement already satisfied: webencodings in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from bleach->kaggle->opendatasets) (0.5.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from importlib-metadata->click->opendatasets) (3.15.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from importlib-metadata->click->opendatasets) (4.5.0)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from requests->kaggle->opendatasets) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from requests->kaggle->opendatasets) (3.4)\n",
      "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
      "Your Kaggle username:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  Maria Tejo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Kaggle Key:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  ········\n"
     ]
    },
    {
     "ename": "ApiException",
     "evalue": "(401)\nReason: Unauthorized\nHTTP response headers: HTTPHeaderDict({'Content-Length': '0', 'Date': 'Wed, 30 Aug 2023 12:48:43 GMT', 'Access-Control-Allow-Credentials': 'true', 'Set-Cookie': 'ka_sessionid=47073e91bb1b4850ea18f36a812bedf5; max-age=2626560; path=/, GCLB=COyjvO21tqPUXQ; path=/; HttpOnly', 'Turbolinks-Location': 'https://www.kaggle.com/api/v1/datasets/download/mlg-ulb/creditcardfraud?datasetVersionNumber=None', 'Strict-Transport-Security': 'max-age=63072000; includeSubDomains; preload', 'Content-Security-Policy': \"object-src 'none'; script-src 'nonce-P2Rhbc2vbP8lQl1ik9mg4Q==' 'report-sample' 'unsafe-inline' 'unsafe-eval' 'strict-dynamic' https: http:; base-uri 'none'; report-uri https://csp.withgoogle.com/csp/kaggle/20201130; frame-src 'self' https://www.kaggleusercontent.com https://www.youtube.com/embed/ https://polygraph-cool.github.io https://www.google.com/recaptcha/ https://form.jotform.com https://submit.jotform.us https://submit.jotformpro.com https://submit.jotform.com https://www.docdroid.com https://www.docdroid.net https://kaggle-static.storage.googleapis.com https://kkb-production.jupyter-proxy.kaggle.net https://kkb-production.firebaseapp.com https://kaggle-metastore.firebaseapp.com https://apis.google.com https://content-sheets.googleapis.com/ https://accounts.google.com/ https://storage.googleapis.com https://docs.google.com https://drive.google.com https://calendar.google.com/;\", 'X-Content-Type-Options': 'nosniff', 'Referrer-Policy': 'strict-origin-when-cross-origin', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mApiException\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_67/861325862.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# download the dataset (this is a Kaggle dataset)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# during download you will be required to input your Kaggle username and password\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://www.kaggle.com/mlg-ulb/creditcardfraud\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/conda/envs/python/lib/python3.7/site-packages/opendatasets/__init__.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(dataset_id_or_url, data_dir, force, dry_run, **kwargs)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Check for a Kaggle dataset URL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_kaggle_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_id_or_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdownload_kaggle_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_id_or_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdry_run\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdry_run\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Check for Google Drive URL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/envs/python/lib/python3.7/site-packages/opendatasets/utils/kaggle_api.py\u001b[0m in \u001b[0;36mdownload_kaggle_dataset\u001b[0;34m(dataset_url, data_dir, force, dry_run)\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0mquiet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                 unzip=True)\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/envs/python/lib/python3.7/site-packages/kaggle/api/kaggle_api_extended.py\u001b[0m in \u001b[0;36mdataset_download_files\u001b[0;34m(self, dataset, path, force, quiet, unzip)\u001b[0m\n\u001b[1;32m   1441\u001b[0m                 \u001b[0mdataset_slug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_slug\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1442\u001b[0m                 \u001b[0mdataset_version_number\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_version_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                 _preload_content=False))\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m         \u001b[0moutfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meffective_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_slug\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/envs/python/lib/python3.7/site-packages/kaggle/api/kaggle_api.py\u001b[0m in \u001b[0;36mdatasets_download_with_http_info\u001b[0;34m(self, owner_slug, dataset_slug, **kwargs)\u001b[0m\n\u001b[1;32m   1575\u001b[0m             \u001b[0m_preload_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_preload_content'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1576\u001b[0m             \u001b[0m_request_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_request_timeout'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1577\u001b[0;31m             collection_formats=collection_formats)\n\u001b[0m\u001b[1;32m   1578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1579\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdatasets_download_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mowner_slug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_slug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: E501\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/envs/python/lib/python3.7/site-packages/kaggle/api_client.py\u001b[0m in \u001b[0;36mcall_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, async_req, _return_http_data_only, collection_formats, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    332\u001b[0m                                    \u001b[0mresponse_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth_settings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                                    \u001b[0m_return_http_data_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollection_formats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                                    _preload_content, _request_timeout)\n\u001b[0m\u001b[1;32m    335\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             thread = self.pool.apply_async(self.__call_api, (resource_path,\n",
      "\u001b[0;32m~/conda/envs/python/lib/python3.7/site-packages/kaggle/api_client.py\u001b[0m in \u001b[0;36m__call_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mpost_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpost_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0m_preload_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_preload_content\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m             _request_timeout=_request_timeout)\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/envs/python/lib/python3.7/site-packages/kaggle/api_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, query_params, headers, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    353\u001b[0m                                         \u001b[0m_preload_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_preload_content\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m                                         \u001b[0m_request_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_request_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m                                         headers=headers)\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"HEAD\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m             return self.rest_client.HEAD(url,\n",
      "\u001b[0;32m~/conda/envs/python/lib/python3.7/site-packages/kaggle/rest.py\u001b[0m in \u001b[0;36mGET\u001b[0;34m(self, url, headers, query_params, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    249\u001b[0m                             \u001b[0m_preload_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_preload_content\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m                             \u001b[0m_request_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_request_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m                             query_params=query_params)\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     def HEAD(self, url, headers=None, query_params=None, _preload_content=True,\n",
      "\u001b[0;32m~/conda/envs/python/lib/python3.7/site-packages/kaggle/rest.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, query_params, headers, body, post_params, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m299\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mApiException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_resp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mApiException\u001b[0m: (401)\nReason: Unauthorized\nHTTP response headers: HTTPHeaderDict({'Content-Length': '0', 'Date': 'Wed, 30 Aug 2023 12:48:43 GMT', 'Access-Control-Allow-Credentials': 'true', 'Set-Cookie': 'ka_sessionid=47073e91bb1b4850ea18f36a812bedf5; max-age=2626560; path=/, GCLB=COyjvO21tqPUXQ; path=/; HttpOnly', 'Turbolinks-Location': 'https://www.kaggle.com/api/v1/datasets/download/mlg-ulb/creditcardfraud?datasetVersionNumber=None', 'Strict-Transport-Security': 'max-age=63072000; includeSubDomains; preload', 'Content-Security-Policy': \"object-src 'none'; script-src 'nonce-P2Rhbc2vbP8lQl1ik9mg4Q==' 'report-sample' 'unsafe-inline' 'unsafe-eval' 'strict-dynamic' https: http:; base-uri 'none'; report-uri https://csp.withgoogle.com/csp/kaggle/20201130; frame-src 'self' https://www.kaggleusercontent.com https://www.youtube.com/embed/ https://polygraph-cool.github.io https://www.google.com/recaptcha/ https://form.jotform.com https://submit.jotform.us https://submit.jotformpro.com https://submit.jotform.com https://www.docdroid.com https://www.docdroid.net https://kaggle-static.storage.googleapis.com https://kkb-production.jupyter-proxy.kaggle.net https://kkb-production.firebaseapp.com https://kaggle-metastore.firebaseapp.com https://apis.google.com https://content-sheets.googleapis.com/ https://accounts.google.com/ https://storage.googleapis.com https://docs.google.com https://drive.google.com https://calendar.google.com/;\", 'X-Content-Type-Options': 'nosniff', 'Referrer-Policy': 'strict-origin-when-cross-origin', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\n"
     ]
    }
   ],
   "source": [
    "# install the opendatasets package\n",
    "!pip install opendatasets\n",
    "\n",
    "import opendatasets as od\n",
    "\n",
    "# download the dataset (this is a Kaggle dataset)\n",
    "# during download you will be required to input your Kaggle username and password\n",
    "od.download(\"https://www.kaggle.com/mlg-ulb/creditcardfraud\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Did you know?__ When it comes to Machine Learning, you will most likely be working with large datasets. As a business, where can you host your data? IBM is offering a unique opportunity for businesses, with 10 Tb of IBM Cloud Object Storage: [Sign up now for free](https://ibm.biz/BdPfxf?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork1047-2022-01-01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"import_libraries\">\n",
    "    <h2>Import Libraries</h2>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting snapml\n",
      "  Downloading snapml-1.14.0-cp37-cp37m-manylinux2014_x86_64.whl (7.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0mm00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from snapml) (0.20.1)\n",
      "Requirement already satisfied: scipy in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from snapml) (1.7.3)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from snapml) (1.21.6)\n",
      "Installing collected packages: snapml\n",
      "Successfully installed snapml-1.14.0\n"
     ]
    }
   ],
   "source": [
    "# Snap ML is available on PyPI. To install it simply run the pip command below.\n",
    "!pip install snapml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/sklearn/utils/validation.py:37: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  LARGE_SPARSE_SUPPORTED = LooseVersion(scipy_version) >= '0.14.0'\n"
     ]
    }
   ],
   "source": [
    "# Import the libraries we need to use in this lab\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize, StandardScaler\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"dataset_analysis\">\n",
    "    <h2>Dataset Analysis</h2>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section you will read the dataset in a Pandas dataframe and visualize its content. You will also look at some data statistics. \n",
    "\n",
    "Note: A Pandas dataframe is a two-dimensional, size-mutable, potentially heterogeneous tabular data structure. For more information: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 43664 observations in the credit card fraud dataset.\n",
      "There are 31 variables in the dataset.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0     0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1     0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2     1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3     1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4     2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62    0.0  \n",
       "1  0.125895 -0.008983  0.014724    2.69    0.0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66    0.0  \n",
       "3 -0.221929  0.062723  0.061458  123.50    0.0  \n",
       "4  0.502292  0.219422  0.215153   69.99    0.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the input data\n",
    "#raw_data = pd.read_csv('creditcardfraud/creditcard.csv')\n",
    "raw_data = pd.read_csv('creditcard.csv')\n",
    "\n",
    "\n",
    "print(\"There are \" + str(len(raw_data)) + \" observations in the credit card fraud dataset.\")\n",
    "print(\"There are \" + str(len(raw_data.columns)) + \" variables in the dataset.\")\n",
    "\n",
    "# display the first rows in the dataset\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, a financial institution may have access to a much larger dataset of transactions. To simulate such a case, we will inflate the original one 10 times.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 436640 observations in the inflated credit card fraud dataset.\n",
      "There are 31 variables in the dataset.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "2   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "3   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "4   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "2  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "3  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "4  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62    0.0  \n",
       "1 -0.189115  0.133558 -0.021053  149.62    0.0  \n",
       "2 -0.189115  0.133558 -0.021053  149.62    0.0  \n",
       "3 -0.189115  0.133558 -0.021053  149.62    0.0  \n",
       "4 -0.189115  0.133558 -0.021053  149.62    0.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_replicas = 10\n",
    "\n",
    "# inflate the original dataset\n",
    "big_raw_data = pd.DataFrame(np.repeat(raw_data.values, n_replicas, axis=0), columns=raw_data.columns)\n",
    "\n",
    "print(\"There are \" + str(len(big_raw_data)) + \" observations in the inflated credit card fraud dataset.\")\n",
    "print(\"There are \" + str(len(big_raw_data.columns)) + \" variables in the dataset.\")\n",
    "\n",
    "# display first rows in the new dataset\n",
    "big_raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1., nan])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_raw_data.Class.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    435290\n",
       "1.0      1340\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_raw_data.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# my notes, I need to delete the rows with nan\n",
    "big_raw_data.dropna(subset=['Class'], how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_raw_data.Class.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    435290\n",
       "1.0      1340\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_raw_data.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 436630 observations in the inflated credit card fraud dataset.\n",
      "There are 31 variables in the dataset.\n"
     ]
    }
   ],
   "source": [
    "print(\"There are \" + str(len(big_raw_data)) + \" observations in the inflated credit card fraud dataset.\")\n",
    "print(\"There are \" + str(len(big_raw_data.columns)) + \" variables in the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row in the dataset represents a credit card transaction. As shown above, each row has 31 variables. One variable (the last variable in the table above) is called Class and represents the target variable. Your objective will be to train a model that uses the other variables to predict the value of the Class variable. Let's first retrieve basic statistics about the target variable.\n",
    "\n",
    "Note: For confidentiality reasons, the original names of most features are anonymized V1, V2 .. V28. The values of these features are the result of a PCA transformation and are numerical. The feature 'Class' is the target variable and it takes two values: 1 in case of fraud and 0 otherwise. For more information about the dataset please visit this webpage: https://www.kaggle.com/mlg-ulb/creditcardfraud.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGZCAYAAABmNy2oAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA+wElEQVR4nO3dd3gU5doG8Hu2Z9N7g4QeekdAiQkgHQtFkRoEFcVyjgj2Y/8UwYaAokhREAQRQaV3UVA6KD1ACCSk975lvj9CRpYkEEKS2Z29f9e1F2R2duaZ2WTvnXfeeUcQRVEEERERAJXcBRARkf1gKBARkYShQEREEoYCERFJGApERCRhKBARkYShQEREEoYCERFJGApERCRhKNwCQRCq9Ni5c6fcpdo4ceIE3nzzTcTFxd103iFDhsDFxQVZWVmVzjN69GhotVokJyffdm1xcXEQBAGLFy++5dfu3LkTgiBg1apVN533zTffhCAI1aiwvOeeew6CIODUqVOVzvPqq69CEAQcOnSoystt0KABxo8fXwMVVk9ycjJeeukltGnTBm5ubjAYDGjatCn+85//4OzZs7LVda09e/bgzTffvOHvJ90ehsIt2Lt3r81j4MCBcHFxKTe9Y8eOcpdq48SJE3jrrbeqFAoTJ05EUVERli1bVuHz2dnZ+OmnnzB48GAEBgbedm3BwcHYu3cvBg0adNvLqisTJ04EACxcuLDC561WK7799lu0b9/e7n4XKrNv3z60adMGCxYswPDhw7F69Wps3LgRU6dOxaFDh3DHHXfIXSKA0lB46623GAq1SCN3AY6kW7duNj/7+/tDpVKVm15dBQUFMBqNNbKs6howYABCQkKwcOFCTJ48udzzy5cvR2FhofTBWF0WiwVmsxl6vb7G9l9dad26Ne644w4sWbIE7733HjQa2z+jzZs34/Lly3jxxRdlqvDW5OTk4P7774fBYMCePXtQr1496bno6GhMmjSpSkdjpAw8Uqhhc+fOxd13342AgAC4urqiTZs2mDFjBkwmk8180dHRaN26NX777TfceeedMBqNmDBhAgDg8uXLGD58ONzd3eHl5YXRo0dj//79FTazHDhwAPfddx98fHxgMBjQoUMHrFy5Unp+8eLFePDBBwEAPXv2lJq4KmuuUavViImJwcGDB/H333+Xe37RokUIDg7GgAEDkJqaismTJ6Nly5Zwc3NDQEAAevXqhd27d9u8pqyJaMaMGXj33XfRsGFD6PV67Nixo8Lmo9jYWDzyyCNo2rQpjEYjQkNDce+991ZYDwAUFRVhypQpCAoKgouLC6KionD48OEK573eihUr0L17d7i6usLNzQ39+vWr0msnTpyIpKQkbNiwocJ9pNfrMXr0aBQVFeH5559H+/bt4enpCR8fH3Tv3h1r16696ToWL14MQRDKHeGVNZtd30y5detW9O7dGx4eHjAajbjrrruwbdu2m65n/vz5SEpKwowZM2wC4VrDhw+3+fnnn39G9+7dYTQa4e7ujj59+mDv3r0284wfPx4NGjQot6yKmvIEQcDTTz+NJUuWoEWLFjAajWjXrh1+/fVXm9dNmzYNANCwYcNyzbXbt29HdHQ0fH194eLigrCwMAwbNgwFBQU33Qf0L4ZCDTt37hxGjRqFJUuW4Ndff8XEiRMxc+ZMTJo0qdy8V65cwZgxYzBq1CisX78ekydPRn5+Pnr27IkdO3bggw8+wMqVKxEYGIgRI0aUe/2OHTtw1113ISsrC/PmzcPatWvRvn17jBgxQvqQHTRoEN577z0ApYFV1sR1o+aaCRMmQBCEcs0jJ06cwL59+xATEwO1Wo2MjAwAwBtvvIF169Zh0aJFaNSoEaKjoys8r/LZZ59h+/bt+PDDD7FhwwY0b968wvUnJibC19cX06dPx8aNGzF37lxoNBp07doVp0+fLjf/K6+8gvPnz+Prr7/G119/jcTERERHR+P8+fOVbiMAvPfeexg5ciRatmyJlStXYsmSJcjNzUVkZCROnDhxw9eOHDkSRqOx3D7KzMzE2rVrMWTIEHh7e6O4uBgZGRmYOnUq1qxZg+XLl6NHjx4YOnQovv322xuu41YsXboUffv2hYeHB7755husXLkSPj4+6Nev302DYfPmzVCr1bj33nurtK5ly5bh/vvvh4eHB5YvX44FCxYgMzMT0dHR+P3336u9DevWrcOcOXPw9ttv48cff4SPjw+GDBkivY+PPvoonnnmGQDA6tWrbZpr4+LiMGjQIOh0OixcuBAbN27E9OnT4erqipKSkmrX5JREqraYmBjR1dW10uctFotoMpnEb7/9VlSr1WJGRob0XFRUlAhA3LZtm81r5s6dKwIQN2zYYDN90qRJIgBx0aJF0rTmzZuLHTp0EE0mk828gwcPFoODg0WLxSKKoij+8MMPIgBxx44dVd62qKgo0c/PTywpKZGmPf/88yIA8cyZMxW+xmw2iyaTSezdu7c4ZMgQafqFCxdEAGLjxo1tlnftc9duV0XLLSkpEZs2bSo+99xz0vQdO3aIAMSOHTuKVqtVmh4XFydqtVrx0Ucflaa98cYb4rW/7vHx8aJGoxGfeeYZm3Xl5uaKQUFB4kMPPVRpPWViYmJErVYrJicnS9Nmz54tAhC3bNlS6baYTCZx4sSJYocOHWyeCw8PF2NiYqSfFy1aJAIQL1y4YDNf2XaXvZ/5+fmij4+PeO+999rMZ7FYxHbt2ol33HHHDbejefPmYlBQ0E229t9lhoSEiG3atJF+v0SxdL8FBASId955pzQtJiZGDA8PL7eM698LURRFAGJgYKCYk5MjTUtKShJVKpX4/vvvS9NmzpxZ4T5ZtWqVCEA8cuRIlbaDKscjhRp2+PBh3HffffD19YVarYZWq8W4ceNgsVhw5swZm3m9vb3Rq1cvm2m7du2Cu7s7+vfvbzN95MiRNj/Hxsbi1KlTGD16NADAbDZLj4EDB+LKlSsVfquuqokTJyItLQ0///yztPylS5ciMjISTZs2leabN28eOnbsCIPBAI1GA61Wi23btuHkyZPllnnfffdBq9XedN1msxnvvfceWrZsCZ1OB41GA51Oh7Nnz1a43FGjRtk0R4SHh+POO+/Ejh07Kl3Hpk2bYDabMW7cOJt9ZzAYEBUVVaUeZBMnToTJZMKSJUukaYsWLUJ4eDh69+4tTfvhhx9w1113wc3NTdpHCxYsqHBbqmPPnj3IyMhATEyMzbZYrVb0798f+/fvR35+fo2s6/Tp00hMTMTYsWOhUv378eHm5oZhw4bhzz//rHZzTc+ePeHu7i79HBgYiICAAFy8ePGmr23fvj10Oh0ef/xxfPPNNzc9SqTKMRRqUHx8PCIjI5GQkIBZs2Zh9+7d2L9/P+bOnQsAKCwstJk/ODi43DLS09Mr7NVz/bSy7qBTp06FVqu1eZSdIE5LS6v2tgwfPhyenp5YtGgRAGD9+vVITk62OcH88ccf48knn0TXrl3x448/4s8//8T+/fvRv3//ctta2fZWZMqUKfjf//6HBx54AL/88gv++usv7N+/H+3atatwuUFBQRVOS09Pr3QdZfuvS5cu5fbfihUrqrTvIiMj0axZM2kfHTt2DIcOHcIjjzwihdTq1avx0EMPITQ0FEuXLsXevXuxf/9+TJgwAUVFRVXaHzdTti3Dhw8vty0ffPABRFGUmvoqEhYWhtTU1CoFR9k+rei9DAkJgdVqRWZmZrW2w9fXt9w0vV5f4Xt+vcaNG2Pr1q0ICAjAU089hcaNG6Nx48aYNWtWtWpxZux9VIPWrFmD/Px8rF69GuHh4dL0I0eOVDh/Rf3mfX19sW/fvnLTk5KSbH728/MDALz88ssYOnRohcuPiIioaunluLi4YOTIkZg/fz6uXLmChQsXwt3dXTppDZS2Y0dHR+OLL76weW1ubm6Fy6zqdQJLly7FuHHjpHMhZdLS0uDl5VVu/uv3Tdm0ij5kypTtv1WrVtm8V7dqwoQJeOmll7Bv3z4sW7YMKpXK5lqDpUuXomHDhlixYoXN9hcXF9902QaDocJ5rw+ssm2ZPXt2pT25btR9uF+/fti8eTN++eUXPPzwwzesqWyfXrlypdxziYmJUKlU8Pb2luqvaDtv58vKjURGRiIyMhIWiwUHDhzA7Nmz8d///heBgYE33S76F48UalDZH71er5emiaKI+fPnV3kZUVFRyM3NLder5fvvv7f5OSIiAk2bNsXRo0fRuXPnCh9lh+Jl9VTlG9e1Jk6cCIvFgpkzZ2L9+vV4+OGHbbrMCoJgs61A6bfl63uh3KqKlrtu3TokJCRUOP/y5cshXnNX2YsXL2LPnj2Ijo6udB39+vWDRqPBuXPnKt1/VRETEwONRoMvv/wS3333HXr37m0TMoIgQKfT2QRCUlJSlXoflfXcOXbsmM30sia9MnfddRe8vLxw4sSJSrdFp9NVup6JEyciKCgIL7zwQqX7ePXq1QBKf+9CQ0OxbNkym32en5+PH3/8UeqRVFZ/SkqKzUWOJSUl2LRp0023vTJV+V1Wq9Xo2rWrdIR+KxcQEo8UalSfPn2g0+kwcuRIvPDCCygqKsIXX3xxS4fTMTEx+OSTTzBmzBi8++67aNKkCTZs2CD9IV3bjvvll19iwIAB6NevH8aPH4/Q0FBkZGTg5MmTOHToEH744QcApf3qAeCrr76Cu7s7DAYDGjZseMNv0gDQuXNntG3bFp9++ilEUSx3bcLgwYPxzjvv4I033kBUVBROnz6Nt99+Gw0bNoTZbK7yNl9v8ODBWLx4MZo3b462bdvi4MGDmDlzZqXdJVNSUjBkyBA89thjyM7OxhtvvAGDwYCXX3650nU0aNAAb7/9Nl599VWcP38e/fv3h7e3N5KTk7Fv3z64urrirbfeummtQUFBGDhwIBYtWlTpPlq9ejUmT56M4cOH49KlS3jnnXcQHBx806uEu3TpgoiICEydOhVmsxne3t746aefyvXwcXNzw+zZsxETE4OMjAwMHz4cAQEBSE1NxdGjR5GamlruaO5anp6eWLt2LQYPHowOHTrg6aefRvfu3aXzOEuXLsXRo0cxdOhQqFQqzJgxA6NHj8bgwYMxadIkFBcXY+bMmcjKysL06dOl5Y4YMQKvv/46Hn74YUybNg1FRUX47LPPYLFYbrpfK9OmTRsAwKxZsxATEwOtVouIiAh899132L59OwYNGoSwsDAUFRVJPcPuueeeaq/PKcl5ltvRVdT76JdffhHbtWsnGgwGMTQ0VJw2bZq4YcOGcr1/oqKixFatWlW43Pj4eHHo0KGim5ub6O7uLg4bNkxcv369CEBcu3atzbxHjx4VH3roITEgIEDUarViUFCQ2KtXL3HevHk283366adiw4YNRbVafdPePteaNWuWCEBs2bJlueeKi4vFqVOniqGhoaLBYBA7duworlmzplyvk7IeRjNnziy3jIp6H2VmZooTJ04UAwICRKPRKPbo0UPcvXu3GBUVJUZFRUnzlfXCWbJkifjss8+K/v7+ol6vFyMjI8UDBw7YrKeiHi+iKIpr1qwRe/bsKXp4eIh6vV4MDw8Xhw8fLm7durVK+0cURXHt2rUiANHHx0csKioq9/z06dPFBg0aiHq9XmzRooU4f/78Cuu5vveRKIrimTNnxL59+4oeHh6iv7+/+Mwzz4jr1q2rsDfZrl27xEGDBok+Pj6iVqsVQ0NDxUGDBok//PBDlbYjKSlJfPHFF8VWrVqJRqNR1Ov1YpMmTcRJkyaJf//9t828a9asEbt27SoaDAbR1dVV7N27t/jHH3+UW+b69evF9u3biy4uLmKjRo3EOXPmVNr76Kmnnir3+or2ycsvvyyGhISIKpVK2g979+4VhwwZIoaHh4t6vV709fUVo6KixJ9//rlK207/EkTxmmNAslvvvfceXnvtNcTHx1f6jZmI6Hax+cgOzZkzBwDQvHlzmEwmbN++HZ999hnGjBnDQCCiWsVQsENGoxGffPIJ4uLiUFxcjLCwMLz44ot47bXX5C6NiBSOzUdERCRhl1QiIpIwFIiISMJQICIiCUOBiIgkDAUiIpIwFIiISMJQICIiCUOBiIgkDAUiIpIwFIiISMJQICIiCUOBiIgkDAUiIpIwFIiISMJQICIiCUOBiIgkDAUiIpIwFIiISMJQICIiCUOBiIgkDAUiIpIwFIiISMJQICIiCUOBiIgkDAUiIpIwFIiISMJQICIiCUOBiIgkDAUiIpIwFIiISMJQICIiCUOBiIgkDAUiIpIwFIiISMJQICIiCUOBiIgkDAUiIpIwFIiISMJQICIiCUOBiIgkGrkLIKoNJosVaXnFSM21fWQVmmCxirBYRVjF0kfpz4AoilCrBGg1KmhVAjRqFbRqFbRqAVq1Ct6uOgR5GBDooUeghwH+bnqoVILcm0pUoxgK5FBEUUR8RgHiMwpsP/DzbP+fXWiCKNZuLWqVAD+30qAIuBoWZf8vDY/SaV5GXe0WQlSDBFGs7T8douqxWEXEpuThn4RsHE/MwT+J2TiZmIPcYrPcpd0SL6MWbUI90SbUE23reaJNPS+EernIXRZRhRgKZBeKTBacTsrFP4mlAXA8IRunknJRbLbKXVqt8HPToXWoJ9qGloZEu3qeCPAwyF0WEUOB5HE5swA7TqficHwmTiTmIDYlD2arc/8qBrjrS48kQr3Qtp4nOoR5semJ6hxDgeqE1SriUHwmtp1KwfaTKTidnCt3SXZPrRLQKdwbfVsGok/LQIT7uspdEjkBhgLVmpwiE3adTsX2UynYdSYVGfklcpfk0JoGuKFPy0Dc0zIQHep7QRDY84lqHkOBatT51DxsO5mCbaeScSAu0+mbhGqLv7se97QIQJ+WgbizsR8MWrXcJZFCMBToth28mIH1fydh+6kUXEjLl7scp2PUqRHZ1A99Wgahd/MAeLvyPARVH0OBqiUtrxirD13Giv2XcC6VQWAv1CoBdzb2xag7wnBPy0Bo1Ry0gG4NQ4GqzGIVsetMClbsv4Ttp1JgsvBXx575u+sxvFM9jOwShjBfo9zlkINgKNBNpeYWY9lf8fh+fzyuZBfJXQ7dIkEA7mrsh1Fdw9C3ZSA0PHqgG2AoUKUOx2fimz1xWP93EkosyryIzNkEexowtns4Rt0RxmsgqEIMBbJRYrZi3d+JWLznIo5eypK7HKolLlo1hnQMxYS7GqJJgJvc5ZAdYSgQgNJRRZfvi8ec7bFIyS2WuxyqI4IARDb1x+ORjdCjqZ/c5ZAdYCg4OatVxE+HE/DptjO4lFEodzkkozsb++KlAc3Rtp6X3KWQjBgKTmzT8SR8tPk0ziTnyV0K2QlBAAa2Dsa0fhFo4MdhNZwRQ8EJ7YlNw4xNp3GE5wyoElq1gBFd6uM/vZvB310vdzlUhxgKTuTIpSzM3HQKf8Smy10KOQijTo1HezTE41GN4abnPbmcAUPBCZxNzsWHm09j0/FkuUshB+XrqsPTvZpgdNdw6DS8zkHJGAoKdjmzAB9vOYM1hxPAcemoJoT5GPF832a4r10IR2lVKIaCAlmtIhbvicOHm0+joMQidzmkQK1CPPD64Jbo2shX7lKohjEUFOZ8ah5eWHUMBy5myl0KKZwgADHdG+DF/s3houPQ3UrBUFAIi1XE17vP4+MtZxR7X2OyTw39XDFzeFt0buAjdylUAxgKCnAmORfTVh3jsBQkG5UATLirIab2i+ANfxwcQ8GBmS1WzNt1Dp9ti+WAdWQXGvm74qMH26FDmLfcpVA1MRQc1InEHExbdRTHE3PkLoXIhlol4LHIRniuT1PoNTxqcDQMBQdTYrZizvaz+GLXOd7khuxas0A3fPhgO46l5GAYCg7kn4RsPL/yKE4n58pdClGVaFQCnohqjGd7N+VFbw6CoeAgVh64hNfW/IMS9iwiB9Q8yB2zHu6AiCB3uUuhm2Ao2DmzxYp3153E4j1xcpdCdFtcdWp8MqI9+rYKkrsUugGGgh3LzC/B5O8OYe95DmBHyiAIwNS+EXiqZxO5S6FKMBTs1InEHDy+5AAuZ/LGN6Q897ULwYzhbXlNgx1iKNihX48lYtoPx1Bo4rhFpFxt63li/rjOCPQwyF0KXYOhYEesVhEfbj6Nz3eek7sUojoR4K7HV+M6o319L7lLoasYCnYip8iE/35/BNtPpchdClGd0mtUmDG8Le5vHyp3KQSGgl04l5qHx749gPOp+XKXQiSbJ6MbY1rfCKhUvE+DnBgKMtt+Khn/+f4IcovMcpdCJLt7WgTg04c78NafMmIoyGjVwct48cdjsPC2aESSiEB3fB3TGfV9jHKX4pQYCjJZsjcOr/98HNz7ROUFeujx3aPd0CTATe5SnA5DQQZf7jqH9zeckrsMIrvm56bHsse6olkgh8aoSwyFOvbx5tP4bHus3GUQOQQfVx2WTLwDrUI85S7FaTAU6tC7v57A179fkLsMIofi6aLFkol3cAjuOsJQqCNv/XIci/6Ik7sMIofkbtBg8SN3oFM47+hW2zjAeR34v3UnGAhEtyG3yIzxC/fxPuR1gKFQyz7YeArzd7PJiOh25RabMW7hPpzgLWhrFUOhFn20+TS+4DhGRDUmu9CEsQv+wlnefbDWMBRqyaytZzGbvYyIalx6fglGf/0X4tI4LExtYCjUgiV/XsQnW8/IXQaRYqXkFmP013/hcmaB3KUoDkOhhv0Rm4a3fj4udxlEipeQVYhxC/Yhu9AkdymKwlCoQRfS8jH5u0MwcywjojpxPi0fzyw/zPHDahBDoYZkF5ow8Zv9/NZCVMd+O5OK6RtOyl2GYjAUaoDZYsXTyw7xfghEMpm/+wJWH7osdxmKwFCoAW//egK7z6bJXQaRU3tp9d84HJ8pdxkOj6Fwm5b8eRHf7r0odxlETq/EbMWkJQeRnFMkdykOjaFwG9jTiMi+pOQW4/ElB1FksshdisNiKFQTexoR2aejl7Lwyuq/5S7DYTEUqoE9jYjs2+rDCZj/23m5y3BIDIVbxJ5GRI5h+sZT2HUmVe4yHA5D4RZ9vOUMexoROQCLVcQzyw7hfGqe3KU4FIbCLTgUn4kveUhK5DByisw88XyLGApVVGSyYOrKo7ycnsjBxKbk4eMtHKCyqhgKVTR9wymc51C9RA7p693ncYgXtlUJQ6EK9p5Lxzd74+Qug4iqySoC0344ymakKmAo3EResRnTVh2FyFYjIod2LjUfn7AZ6aYYCjfx7q8ncDmzUO4yiKgGfP37BY6PdBMMhRvYcToF3++/JHcZRFRDLFYRU9mMdEMMhUpkF5jw0o/H5C6DiGrYudR83i73BhgKlXj953+QnFMsdxlEVAu+3s1mpMowFCqw4e8rWHskUe4yiKiWWKwipq06hmIzm5Gux1C4TlpeMV5b84/cZRBRLYtNycMnW87KXYbdYShc5711J5GeXyJ3GURUB+bvPo8jl7LkLsOuMBSucTwxGz8dSZC7DCKqIxariBdXHePwNddgKFxj+oZTvEiNyMmcTs7Fj4cuy12G3WAoXLX7bCqHxCZyUrO2nuVJ56sYCgBEUcT760/JXQYRySQhqxBL9l6Uuwy7wFAA8NPhBJy4kiN3GUQko7k7YpFbxFvsOn0oFJst+Ggzr24kcnaZBSZ8xZtoMRS+2ROHhCwOeEdEwILfLyAtz7lHMnDqUMguMGHujnNyl0FEdqKgxILZ25z7gjanDoW5O2ORXcg2RCL617J98biUUSB3GbJx2lBIyCrE4j1xcpdBRHbGZBHx0ebTcpchG6cNhY82nUaJ2Sp3GURkh9YeTcSJROfskeiUoXAiMQdrOJwFEVVCFIGZm5zz2iWnDIXPd8aCQ50Q0Y3sOJ2KfRcy5C6jzjldKCRmFWLjP0lyl0FEDmDWNue7hsnpQmHxnjiYeZhARFXwR2w6ziTnyl1GnXKqUMgvNmP5vni5yyAiB7Lojzi5S6hTThUKKw9cQm6RWe4yiMiBrDmcgKwC57nxltOEgtUqOl3iE9HtKzRZ8P3+S3KXUWecJhS2nkxGvBNfpUhE1bdk70WnuTub04TCkj85VjoRVU9CViE2H3eOXotOEQrx6QX4PZZ3VSOi6vvuL+fopOIUobBsXzzvvUxEt+WPc2mIT1d+E7TiQ6HEbMWqg85zkoiIaocoAisOKP9oQfGhsPF4EtLynKc7GRHVnlUHLyv+hLPiQ2HZXzzBTEQ1IzmnGNtPpchdRq1SdChcyijAn+edb0ArIqo93yt8VARFh8LmE8lyl0BECrPzTCpScorkLqPWKDsUnKRfMRHVHYtVxJaTyv3CqdhQyMwvwYGLmXKXQUQKtO2kcs8rKDYUtp5MVnwvASKSxx+xaSgsschdRq1QbCjwfAIR1ZZisxW7z6bKXUatUGQoFJZYFPuGEZF9UGoTkiJD4bezqSgyWeUug4gUbPvpFIgKHD9HkaGw+TibjoiodqXmFuPIpSy5y6hxigsFi1XE9lMMBSKqfUpsQlJcKOy7kIHMApPcZRCRE9iqwOsVFBcKm0/wgjUiqhunknJxOVNZw2krLhS2sCsqEdUhpTUhKSoUjidm43JmodxlEJETUVoTkqJCYU9sutwlEJGT+et8BvKKzXKXUWMUFQpHL2fJXQIROZkSixV7FHQPeEWFwrHL2XKXQEROSEmfPYoJhcz8EsRnKKsXABE5hr8TGAp2h01HRCSX44kMBbujpMM3InIsaXkluJKtjJ6PigmFowocg4SIHMffCvliqpxQUMgbQkSO6Z/EHLlLqBGKCIXErEKk5RXLXQYRObF/FHKyWRGhwKYjIpKbUnogKSMU2HRERDJLzS1Gck6R3GXcNkWEwjF2RyUiO6CEJiSHDwVRFBVz2EZEjk0Jn0UOHwrnUvORW6ScwaiIyHHxSMEOnE3OlbsEIiIAPFKwC4nZjn9ih4iUITmnGOkO3j3e4UMhSSGXlhORMlxx8C+qjh8KOY6dykSkLCm5DAVZ8UiBiOxJioN/UXX4UHD0QzUiUpaUXIaCbERRdPhUJiJlYfORjNLzS1BiscpdBhGRJNnBv6g6dCgksemIiOwMm49kxFAgInuT6uCD4jl0KFxx8J1PRMqTmlcMURTlLqPaHDoU2B2ViOyNySIis8AkdxnV5uCh4Nhtd0SkTI7cA8mxQyGHRwpEZH8cuau8Q4eCI+94IlIuR74Dm0OHQqHJIncJRETlOHK3VIcOBRMvXCMiO5RX7Lg3/tJU50Wff/45Zs6ciStXrqBVq1b49NNPERkZWen8u3btwpQpU3D8+HGEhITghRdewBNPPFHtosuUmOUJBWtxAbJ2L0XB2b2wFmRDF9AI3vc8Dn1wMwCAJT8TmTsXoyjuMKxF+dDXbwWfeyZB6xN64+UW5SHztyUoPLMHlqI8aDwD4dNrIlwad6nSegEg6/fvkH9yNyy5qRBUGuiCmsDr7nHQh0RI82Rsm4/8f7ZB0LrAO3o8XFtGSc/ln9yN/OPbETD8jZrcZUROxWJ1oi6pK1aswH//+1+8+uqrOHz4MCIjIzFgwADEx8dXOP+FCxcwcOBAREZG4vDhw3jllVfw7LPP4scff7zt4uUKhfSNs1EUdwR+g59H8IQ5MDTsgOTvX4M5N610PKbV78KclQT/oa8hePwsaDwCkLziNVhLKm9nFC0mJK/4HyzZyfB74GWEPvYlfAc8A7W7b5XWW0brEwqfPk8geMJcBI6eAY1nYOlyC0rvCFUQ+xfyT+5CwEPvwDt6PNI3zIKlMAdAaShl7f4WPn2frKU9R+QczBbHDYVbPlL4+OOPMXHiRDz66KMAgE8//RSbNm3CF198gffff7/c/PPmzUNYWBg+/fRTAECLFi1w4MABfPjhhxg2bNhtFW+SYcdbTcUoOP0H/If9D4b6rQEAXj1Go+Dsn8g9vAFurXuhJPE0gifMhc4/HADg0/dJXJ49Bvknd8G9Xb8Kl5t3bAusRbkIGjMTgrr0bdF4BlR5vd53jwUAuLaMtlmud69HkXdsM0pSLsClQXuY0i/BUL8N9MFNoQ9uioxt82HOSoLaxQOZOxfBvcMgaDwCQM4p99A6ZO9bDUteBnR+YfDu/Zj0+3a9osvHkbVzMUzplyGai6H2CIB7+/7w6PKAzXz5p/9A9u6lMGVdgdYrGF53j4Wx2Z3S85e/mABLTkq55bt1GATfq19Qsv9ajZx9qwEAnt2G26yjOPE0MjZ/jqBxH0NQqW9zD9QMs9Vxm7Zv6UihpKQEBw8eRN++fW2m9+3bF3v27KnwNXv37i03f79+/XDgwAGYTLd3gYcsg+FZLYBohaDW2kwWNDoUXz4O0WKSfpaeU6khqDUovnyi0sUWxP4FfUhzZGz5Apdmj0HigsnI3rsSotVSpfVWRLSYkHtkIwS9K3QBDQEAOv+GKEmKhaUoD8VJsRDNxdB4h6Do8nGUJJ+De6d7b3mXkDLkn/wNGdvmw7P7QwgZ/xn09Voh5Yc3Ya7gAxsAVFoD3DsORuCo6Qh59At43jkCWbuXIPfIRmme4oSTSFv7AVxb9UTII7Ph2qonUtd+gOLE09I8wTGfoN5TS6RHwIh3AQCuze8CAJSkxiH79+/gd980+N07FVm/fYuS1DgAgGgxI33TXPj0e8puAgEAzDXQfPTbb7/h3nvvRUhICARBwJo1a276ml27dqFTp04wGAxo1KgR5s2bd8vrvaVQSEtLg8ViQWBgoM30wMBAJCUlVfiapKSkCuc3m81IS0ur8DVVIVfTkUpvhD6kObL3fA9zbjpEqwV5x3egJPEMLPmZ0PrUg9ojAFm7voGlKA+ixYTsP3+AJT8TlryMSpdrzkpG/uk/IFqtCHjwTXh2H4GcfT8he+/KKq33WgWx+xD/8XDEfzgUuQfWIHDEO1AbPQEALo06wbVVNJK+eQ7p6z6B36DnoNLqkbHpc/j0exq5h9cjYf4kJC2dhpLUi7W3I8nu5OxfA7e2feDerh+0fvXhc8/jULv7Iffw+grn1wU2hmvLKOj8w6HxDIRbq54wNOxo8yUl58DPMDToAM/uD0HrWx+e3R+CIbwdcg6sleZRGz2hdvOWHoWx+6DxCoa+fhsAgCntErT+DeAS3g4uDdpD698ApvTLpcvftxqG+q1szqvZA0sNtGLk5+ejXbt2mDNnTpXmr6mm+mqdaBYEweZnURTLTbvZ/BVNvxUi5Guz8x38PNI3zELC5zGAoIIuqPSPoyT5HAS1Bv5DXkH6hlm4POthQFDB0KA9DI063XihohVqoxd8+z8NQaWGPqgJLHkZyNm3Gl53jbzpeq9lCGuL4Ec+g7UgB7lHNyF17QcIHvsR1K5eAEqbnbx6jJbmz/r9OxgatIegUiN77wqETJiLwth9SF/3MYLHz6rRfUf2SbSYUJIUC89uw22muzTsgOKEU1VaRknyORQnnIRX5FhpWnHCKXh0uf+6ZXa0CYXr68g/sRMeXR6QPh90/g1gzkwoPWIRAXNGAnR+4TBlJiLv760Ijvn0Fra0btTEkcKAAQMwYMCAKs9fU031txQKfn5+UKvV5Y4KUlJSyh0NlAkKCqpwfo1GA19f3wpfUxWq2wiU26X1DkbQqOmwlhTBWlIAjZsPUtd+AI1n6T7QBzVByCOzYS3Oh2gxQ230xJVvp0AX1LTSZardfEqbma45BNb61oclPxOixQRBrb3pesuodAaodCGAdwj0oc2R8NVjyDu2GZ7dHyq3XlP6JeSf2Ing8Z8h79gWGOq1htroCWPzSKRvmAVrcQFUemMN7Tn7phasMKhFGFVW6FVWuKitMFz9v0FthV6wlP5fZYVOZYFesEKvskB39V8tLNCqrNDBAq1ghU4wQytYoUXpvxqYoYUFmqsPrWCGWrRAAzM0sEAlmqGGBWrRArVohhpmqKxmqEUzVFcfgmiBUAuDrSVml6CJaMWK8J/RLXSnNH1G8GV8dykFR0Pfq/S1Tf53AGl5JpitIl4dUB8v9z8I4CAAwLMgDR/X24URof82na64kopJu9JwsoJl/ngoDeOLc3CgzwmEeF59PhSYnxuAOT9OBgB8cn8IHmu3BIPmHMfHw4JgyX4N/7fxEjQqFT4c1gA9mnje/g65TSWu9wBoV6frrKypfsGCBTCZTNBqtZW80tYthYJOp0OnTp2wZcsWDBkyRJq+ZcsW3H///RW+pnv37vjll19spm3evBmdO3eucpEVkS8S/lX64WuApSgPhRcOwTv6Edvn9a4AAFNGAkqSYuEVOabSZelDWyD/xC6IohWCUNqqZ8pMKA2L684j3Gy95YiQznXYTBZFpG+cA++ej0KlcwFEK0Tr1f7VZf+KjnvC7FZZRBXyzUA+7Kdt+nqCIMKgssKgEmFQW+FyTYDpBAv0aiv0ggi9qjTASoOs9P86oTSs9MK/oaWDFVrBgpziLAAHcNylAzTG4NLwEixI1VhhUuXgorEV1CgNsGtDSy1a8Mu0HigsKsbB8xl4c81ZNPI3YkQnH6iu/g5pLIXQFWdAsJoAqxmawuzS7cg4CUG0vQB1ye58DGiiQWPzGSD93+nPtgCebVF2ni4Ni7clwlNlRrRnAiLm5GH/Y664nCNi9MITuPAfN+g18n5CuNRrU+frvFlTfXBwcJWWc8vNR1OmTMHYsWPRuXNndO/eHV999RXi4+Ol6w5efvllJCQk4NtvvwUAPPHEE5gzZw6mTJmCxx57DHv37sWCBQuwfPnyW121DTmPFArPl34L0viEwpx5BZk7F0LrEwq3NvcAAPJP/Q610QNqjwCYUuOQsfUrGJt2g0vDjtIy0n79CGp3X3hHjQcAuHcYiNxDvyJz61dw73QvTJmJyN77AzyuOfF7s/VaS4qQvXcFjE26Qu3mA0thDvIOr4c5Nw3GiB7ltiPv6KbSo4KmXQGUBlPW78tQnHAKhecPQusbBpXBreZ3IFWbKAootKhRaAFQgwNxihYTIHyKt0/Vh9H6b8+gjEvnUKLNQ/+zFX/ps1EfsHb6Ho/9sgNvBn0EALAaH8GzV/rjtXoPSLPlpK+B2bgWDQsXQRBEGFUiDGoLkJOEQ+cno8PIqRiq71QaZsLVo7SrR2QGlQWm/BzM/306nnnuWbxxOR7eQZuxt/Uz0AoW5K1+B/PU49C0np8UbFqYoUXpkZpGMEMjlh6plYVaadCZoRKvTrOaobp65KayXnOUZi39WRBNEKxmKeQEqwmwmAGrCULZlyhBnuuCa6Kp/pZDYcSIEUhPT8fbb7+NK1euoHXr1li/fj3Cw0u7X165csXmmoWGDRti/fr1eO655zB37lyEhITgs88+u+3uqDJmQulFZL99A3NuGtQGdxgj7oTX3eOkrqSWvAxkbv8alvwsqN284daqFzzvethmGeacVJtfHI2HPwIfehsZ275G7sKnoXH3hUfn++DRdViV1yuoVDBlXEbqmm2wFOZA7eIBXVBTBI3+QOoeW8aSn4nsvSsRNGamNE0fEgGPO4YgZdVbUBk94TfouRrfd2SfBLUWuqAmKIw7YtNdtCjuCFyufmmoElGEaP43rfShzVEYd9imC2nhhcPQh7a4OruAfIuAfIsKWQd+g9rohfTQHsjIrvxoLe2X5dB1GI7FuZ1QkFyMrEItXr/QEgCQbxLwQXwEdMWNql5zDVILpUdxDyMM/6vjdddUU321TjRPnjwZkydPrvC5xYsXl5sWFRWFQ4cOVWdVlbqdk9S3y7VFJFxbVH4Ft0fn++DR+b4bLiNo1PRy0/ShLRA87qNqr1fQ6BAw5NUbrreM2tUb9Z5cWG66110jpRPb5Fw8ujyAtF8/hj6oCfQhLZB7dCPMOalwbz8QAJC5azEsuenwG/w8ACD30K9Qe/hD61MPAFB8+QRy9v1k063ZvdN9SF72IrL/XAVj064oOPsXii4eQdDoGTbrFkUr8v7eCtfWvW/YtbTwwmGYMhPhO3gKAEAX3AzmjMsoPHeg9CJOlRqam4wcUJssogr5FkBU624+cw2rqab6aoWCvVAJgANfTU5kV1xb3A1rYS6y/vgelvwM6PzCEfDgm9JFlJa8zNIj3KtEUUTWrm9gzk4GBDW03sHwjh4Pt/b9pXkM9VrA774XkLV7KbJ2L4XGKwj+971oM+wKUHpEYslJhVvbPpXWZzUVI2PrPPjf96J03k3j7gfveyYhbcOnENRa+F7tYi03g/b2m4/y8vIQGxsr/XzhwgUcOXIEPj4+CAsLq7WmekF04PvGtXljE3IdeOApIlKmKX2a4dnelfc2rIqdO3eiZ8+e5abHxMRg8eLFGD9+POLi4rBz507puV27duG5556Txpl78cUXb3mcOYcOheiZOxCXXiB3GURENl4Z2ByP391Y7jKqxaGHzvZzk/8wkYjoei5a++3WfDMMBSKiGqZnKMjD163uz/ATEd2Mu95x+/A4dCjwSIGI7FGwl4vcJVSbY4eCO0OBiOxPiJdB7hKqzbFDwZXNR0RkX3QaFfwduBXDsUOBRwpEZGeCPQ2yjrhwuxw7FBw4jYlImUId+HwC4PChwOYjIrIvIQwF+bgbtNBrHHoTiEhhGAoyYxMSEdmTUAfueQQoIhTYhERE9iPUy7FvX+vwoRDo4dipTETK4sjXKAAKCIXmQe5yl0BEJOE5BZm1DPGQuwQiIgCAr6sOBgceDA9QQigEe8pdAhERAMc/SgAUEAr1fVzgbnDcEQmJSDnqeTMUZCcIAloEswmJiOTXOtTxWy4cPhQAoCVDgYjsQIf6XnKXcNuUEQo82UxEMlMJQDuGgn3gkQIRya1ZoDtcHfiOa2UUEQrNAt2hVTvuULVE5Pg6hHnJXUKNUEQo6DQqNAngRWxEJJ8O9b3lLqFGKCIUADYhEZG8eKRgZ3iymYjk4m7QoEmAm9xl1AjlhAKPFIhIJu3rezn0LTivpZxQCPGAShnvCRE5mPYK6IpaRjGh4OmiRdt6XnKXQUROSCnnEwAFhQIA9IwIkLsEInJCSul5BCgsFHo1ZygQUd1q4GuEt6ty7gCpqFBoHeoBf3fes5mI6k7HMOUcJQAKCwVBEBDdzF/uMojIifRUWAuFokIBYBMSEdUdnUaluM8cxYVCj6Z+HAeJiOrE3U39FDEI3rUUFwruBi26NPCRuwwicgL9WwfLXUKNU1woAOyaSkS1T6sW0KdFoNxl1DhlhoLC2viIyP50a+QLT6NW7jJqnCJDoUmAG8J8jHKXQUQK1r91kNwl1ApFhgIA9Ixg11Qiqh0qAejbkqHgUNiERES1pXMDH8VeKKvYUOjWyBduCusqRkT2YYBCm44ABYeCQavGoDbK6y5GRPISBOWeTwAUHAoA8FCXenKXQEQK07aeF4I9XeQuo9YoOhQ6hfugsb+r3GUQkYIouekIUHgoAMCDnevLXQIRKYQgAAMVeBXztRQfCkM7hkLD+3QSUQ3o0cQPYb7KvgZK8aEQ4G5ANK9ZIKIaMLZbuNwl1DrFhwIAPNwlTO4SiMjBhXq5oLcCxzq6nlOEQq/mAajnrdzeAkRU+0Z1DYPaCZqinSIUVCoBo7sq/7CPiGqHTq3CiC7O0WnFKUIBAB7uUh96jdNsLhHVoIFtguDnpsxhLa7nNJ+S3q463NsuRO4yiMgBxdzZQO4S6ozThAIAxHRvIHcJRORgujTwRocwb7nLqDNOFQpt6nmiQ5iX3GUQkQN5/O7GcpdQp5wqFABgcnQTuUsgIgfRyN8V97RwrmH4nS4U+rQMRPv6XnKXQUQO4LHIRhAE5XdDvZbThQIATO0bIXcJRGTn/Nz0GNoxVO4y6pxThkKPpn7o1shH7jKIyI7FdA+HXqOWu4w655ShAADT+vFogYgq5uemxyM9GspdhiycNhQ6hfugF+/jTEQV+O89TZ32dr5OGwoA8HzfZnCyc0hEdBNNA9ww8g7nHUTTqUOhVYin4m+YQUS35pWBLZxi4LvKOHUoAMBzfZo59S8AEf2rRxM/9HTyZmWnD4UmAW54oL3zdTsjIlsqofQowdk5fSgApSeVdGruCiJnNqxjPbQM8ZC7DNnxkxBAfR+j04yVTkTlGXVqTGU3dQAMBckzvZrARet8F6oQEfBoZCMEehjkLsMuMBSuCvAw4Lk+TeUug4jqWIC7Hk9ENZK7DLvBULjGxB6N0K6ep9xlEFEder5vMxh1znmhWkUYCtdQqwTMGN6OJ52JnETzIHc82InnE6/FT7/rRAS5Y3JP57qpBpEzEgTg9cEtoeJ1SjYYChV4qmcTNA9yl7sMIqpF47qF484mfnKXYXcYChXQqlX4YFhbXulMpFCN/V3xMi9UqxBDoRLt6nthopMOnUukZBqVgE9GtIeBXdArxFC4gSl9mqGhn6vcZRBRDXqmV1O0recldxl2i6FwAwatGtOHtuHw2kQK0b6+F57u1UTuMuwaQ+Emujbyxeiuzju2OpFSuGjV+GREe54rvAmGQhW8NKAFQr1c5C6DiG7DK4NasDm4ChgKVeCm1+D/hrSWuwwiqqaoZv4Y2y1c7jIcAkOhiqIjAvD43RwfhcjReBu1mDm8rdxlOAyGwi14sX9z9ODFLkQO5f+GtEEAR0CtMobCLVCrBMwZ1QH1fXh+gcgRDOkQioFteB/2W8FQuEVeRh2+GtuZ914gsnON/Fzx1v2t5C7D4TAUqqFFsAdmsI2SyG55G7VYOL4LPAxauUtxOAyFarq3XQgm8cQzkd3RqVWYN6YTGrD7abUwFG7DC/2bI7IpTzwT2ZP3h7ZB10a+cpfhsBgKt0GtEjB7ZAeE+RjlLoWIADzVszGGdaondxkOjaFwm7yMOnw5thOMOp54JpLToDbBmNo3Qu4yHB5DoQa0CPbAzOHt5C6DyGm1r++Fjx5qB4GjV942hkINGdQ2GE9E8TaeRHUt1MsF88d15v0RaghDoQa90C8CA1oHyV0GkdNw12uwcHwX+Lvr5S5FMRgKNUilEjDr4Q64u5m/3KUQKZ5aJWD2qA6I4P3UaxRDoYbpNCp8OaYT7mjgI3cpRIr2xr0tER0RIHcZisNQqAUuOjUWjO+MNqGecpdCpEiT7m6Ecd0byF2GIjEUaom7QYtvJtyBpgFucpdCpCiPRTbEywNbyF2GYjEUapGPqw5LH+2KBr68uI2oJjx+dyO8Oqil3GUoGkOhlgV6GLBiUnc04jgsRLfl8bsb4RUeIdQ6hkIdCPQwYPnj3dDIn8FAVB0MhLrDUKgjgR4GfP94NzRmMBDdkklRDIS6JIiiKMpdhDNJzS3GyPl/IjYlT+5SiOzetH4ReKpnE7nLcCoMBRmk5RVj7IJ9OHklR+5SiOySIABv398aY7uFy12K02EoyCS/2Iz/fH8YW0+myF0KkV3RqAR8+GA7PNAhVO5SnBJDQUZWq4j3N5zE/N0X5C6FyC7oNSrMHdUR97QMlLsUp8VQsAPf74vH/9b+A5OFbwU5L2+jFl+M6YRuvGuarBgKdmLvuXQ8+d1BZBWY5C6FqM61DvXAvDGdUM+bF3rKjaFgR+LS8jHhm/04n5ovdylEdWZox1C8N6QN74dgJxgKdia70ITJ3x3EH7HpcpdCVKu0agGvDWqJmDsbyF0KXYOhYIfMFite//k4lv0VL3cpRLXCz02Pz0d3xB0NOcS8vWEo2LEFv1/Ae+tPwmLlW0TK0SHMC/PGdEKgh0HuUqgCDAU7t+NUCp5dfhi5xWa5SyG6baO6huHNe1tBp+EIO/aKoeAALmUU4PkfjmLfhQy5SyGqFp1GhXfub4URXcLkLoVugqHgIKxWEQt+v4CZm0+jxGyVuxyiKgv2NOCLMZ3Qvr6X3KVQFTAUHMyZ5FxMWXkE/yRw3CSyf72aB2DG8Lbwc9PLXQpVEUPBAZksVszedhaf7zwHM09Ckx3yddXh9Xtb4v72HL/I0TAUHNiRS1mYsvIIL3YjuzKkQyheH9wS3q46uUuhamAoOLgikwXTN5zCN3vjwHeS5BTq5YJ3h7RGz4gAuUuh28BQUIg9sWmY+sNRJGYXyV0KORmVAIztFo4X+jeHq14jdzl0mxgKCpJTZMKbPx/H6kMJcpdCTqJJgBs+GNYGncJ5ZbJSMBQU6I/YNPzfupM4wTu7US3RqgU8GdUYT/VqAr2GA9kpCUNBoaxWET8dTsBHm0+zSYlqVLv6XvhgWBs0D/KQuxSqBQwFhSsyWbDg9wuYt/Mch8qg2xLkYcAzvZtgZJcwqFSC3OVQLWEoOIn0vGJ8tu0slu2L5x3e6Jb4uekxOboxRnUN4z0PnABDwclcSMvHBxtOYePxJLlLITvnbdTi8bsbY/ydDeCiYxg4C4aCkzoQl4H/W38Sh+Oz5C6F7Iy7QYNHezTCxMiGcGMXU6fDUHBy645dwYxNp3AxvUDuUkhmrjo1xt/VAI9HNoanUSt3OSQThgLBZLHil6OJmL/7Ak6yG6vTMWhVGNM1HE9GN4YvB65zegwFsvFHbBrm7z6PXWdSOWyGwuk0KjzcpT6e7tkEAbwLGl3FUKAKnU3Oxde7L+CnIwm8f4PC1PN2weiu4RjRpT58OGgdXYehQDeUnleMlQcuY9m+i7iUUSh3OVRNKgG4u5k/xnYLR8+IAF5nQJViKFCVWK0idp1NxXd/XsT2UyngbRwcg5+bDsM61sPoruEI8zXKXQ45AIYC3bKErEIs/ysePx66jCscQsPuaNUCekYE4MHO9dEzwh8atUruksiBMBSo2kRRxNHL2dj4TxI2H0/C+TTe7EdOLYI9MLxTPTzQPoS9iKjaGApUY84k52LTP0nYeDwJxxPZtbW2qVUCOtT3QnSEP3q3CESLYA5QR7ePoUC14lJGATYdT8Lm48k4cDGD5yBqiJ+bDnc380fPiADc3dSfF5lRjWMoUK1LyyvGlhPJ2HQ8CXti01FiYRfXqlIJQPv6XoiOCEDPiAC0DvWAILDnENUehgLVqdwiEw5czMSR+CwcuZSFo5ezkFVgkrssu+LrqkNUM39ERfgjqpk/vIy8loDqDkOBZBeXlo8jl7Kkx4krOU5zwZyHQYPmwR5oGeyBFsHuaBXiiVYhPBog+TAUyO6UmK04eSVHComjl7JwIT3foYfdEASgga8rWgS7o0WQB1oEe6BFiAdCvVzkLo3IBkOBHEJ2gQmxqblIzCrClexC6d8r2UVIzCpCen6xXYSGUaeGj6sOQR4GNA92L/3wD/ZA8yB3GHUchprsH0OBFKHEbEVyThESs64GRXYhrlwNjpTcYhSWWFBstqLYXPpvidmKYrMVlpt0izJoVfB11cPXTQdfVx18XPXwc9PBx7X04eemh4+r7urzet6MhhweQ4GcmsUqwnr1T6CsFb+sPV8AOEYQOR2GAhERSTgoChERSRgKREQkYSgQEZGEoUBERBKGAhERSRgKREQkYSgQEZGEoUBERBKGAhERSRgKREQkYSgQEZGEoUBERBKGAhERSRgKREQkYSgQEZGEoUBERBKGAhERSRgKREQkYSgQEZGEoUBERBKGAhERSRgKREQkYSgQEZGEoUBERBKGAhERSRgKREQkYSgQEZGEoUBERBKGAhERSRgKREQkYSgQEZGEoUBERBKGAhERSRgKREQkYSgQEZGEoUBERBKGAhERSRgKREQkYSgQEZGEoUBERBKGAhERSRgKREQkYSgQEZGEoUBERBKGAhERSf4fabpQIZBKMiIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get the set of distinct classes\n",
    "labels = big_raw_data.Class.unique()\n",
    "\n",
    "# get the count of each class\n",
    "sizes = big_raw_data.Class.value_counts().values\n",
    "\n",
    "# plot the class value counts\n",
    "fig, ax = plt.subplots()\n",
    "ax.pie(sizes, labels=labels, autopct='%1.3f%%')\n",
    "ax.set_title('Target Variable Value Counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, the Class variable has two values: 0 (the credit card transaction is legitimate) and 1 (the credit card transaction is fraudulent). Thus, you need to model a binary classification problem. Moreover, the dataset is highly unbalanced, the target variable classes are not represented equally. This case requires special attention when training or when evaluating the quality of a model. One way of handing this case at train time is to bias the model to pay more attention to the samples in the minority class. The models under the current study will be configured to take into account the class weights of the samples at train/fit time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The credit card transactions have different amounts. Could you plot a histogram that shows the distribution of these amounts? What is the range of these amounts (min/max)? Could you print the 90th percentile of the amount values?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum amount value is  0.0\n",
      "Maximum amount value is  7879.42\n",
      "90% of the transactions have an amount less or equal than  nan\n"
     ]
    }
   ],
   "source": [
    "# we provide our solution here\n",
    "plt.hist(big_raw_data.Amount.values, 6, histtype='bar', facecolor='g')\n",
    "plt.show()\n",
    "\n",
    "print(\"Minimum amount value is \", np.min(big_raw_data.Amount.values))\n",
    "print(\"Maximum amount value is \", np.max(big_raw_data.Amount.values))\n",
    "print(\"90% of the transactions have an amount less or equal than \", np.percentile(raw_data.Amount.values, 90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([149.62,   2.69, 378.66, ...,  29.72,  60.01, 745.56])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#There are also nan in the Amount column? No, it's doesn't seem like it\n",
    "big_raw_data.Amount.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>436630.000000</td>\n",
       "      <td>436630.000000</td>\n",
       "      <td>436630.000000</td>\n",
       "      <td>436630.000000</td>\n",
       "      <td>436630.000000</td>\n",
       "      <td>436630.000000</td>\n",
       "      <td>436630.000000</td>\n",
       "      <td>436630.000000</td>\n",
       "      <td>436630.000000</td>\n",
       "      <td>436630.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>436630.000000</td>\n",
       "      <td>436630.000000</td>\n",
       "      <td>436630.000000</td>\n",
       "      <td>436630.000000</td>\n",
       "      <td>436630.000000</td>\n",
       "      <td>436630.000000</td>\n",
       "      <td>436630.000000</td>\n",
       "      <td>436630.000000</td>\n",
       "      <td>436630.000000</td>\n",
       "      <td>436630.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>26887.915901</td>\n",
       "      <td>-0.233305</td>\n",
       "      <td>0.031605</td>\n",
       "      <td>0.700511</td>\n",
       "      <td>0.191717</td>\n",
       "      <td>-0.243616</td>\n",
       "      <td>0.099243</td>\n",
       "      <td>-0.117611</td>\n",
       "      <td>0.051500</td>\n",
       "      <td>0.173597</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026791</td>\n",
       "      <td>-0.110083</td>\n",
       "      <td>-0.039981</td>\n",
       "      <td>0.009708</td>\n",
       "      <td>0.136439</td>\n",
       "      <td>0.022624</td>\n",
       "      <td>0.006871</td>\n",
       "      <td>0.005107</td>\n",
       "      <td>90.313927</td>\n",
       "      <td>0.003069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12814.811924</td>\n",
       "      <td>1.881477</td>\n",
       "      <td>1.614104</td>\n",
       "      <td>1.524289</td>\n",
       "      <td>1.407336</td>\n",
       "      <td>1.409002</td>\n",
       "      <td>1.310496</td>\n",
       "      <td>1.272766</td>\n",
       "      <td>1.214445</td>\n",
       "      <td>1.226177</td>\n",
       "      <td>...</td>\n",
       "      <td>0.739610</td>\n",
       "      <td>0.637123</td>\n",
       "      <td>0.568360</td>\n",
       "      <td>0.592318</td>\n",
       "      <td>0.437458</td>\n",
       "      <td>0.503347</td>\n",
       "      <td>0.390441</td>\n",
       "      <td>0.342266</td>\n",
       "      <td>238.439495</td>\n",
       "      <td>0.055313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-56.407510</td>\n",
       "      <td>-72.715728</td>\n",
       "      <td>-32.454198</td>\n",
       "      <td>-5.172595</td>\n",
       "      <td>-42.147898</td>\n",
       "      <td>-26.160506</td>\n",
       "      <td>-26.548144</td>\n",
       "      <td>-41.484823</td>\n",
       "      <td>-8.507059</td>\n",
       "      <td>...</td>\n",
       "      <td>-20.262054</td>\n",
       "      <td>-8.593642</td>\n",
       "      <td>-26.751119</td>\n",
       "      <td>-2.836627</td>\n",
       "      <td>-7.495741</td>\n",
       "      <td>-1.438650</td>\n",
       "      <td>-8.567638</td>\n",
       "      <td>-9.617915</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18716.000000</td>\n",
       "      <td>-0.980298</td>\n",
       "      <td>-0.539106</td>\n",
       "      <td>0.225524</td>\n",
       "      <td>-0.715683</td>\n",
       "      <td>-0.848293</td>\n",
       "      <td>-0.637899</td>\n",
       "      <td>-0.599202</td>\n",
       "      <td>-0.149296</td>\n",
       "      <td>-0.579461</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.233426</td>\n",
       "      <td>-0.530961</td>\n",
       "      <td>-0.179119</td>\n",
       "      <td>-0.322003</td>\n",
       "      <td>-0.128050</td>\n",
       "      <td>-0.329467</td>\n",
       "      <td>-0.063373</td>\n",
       "      <td>-0.006856</td>\n",
       "      <td>7.570000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>31883.000000</td>\n",
       "      <td>-0.244869</td>\n",
       "      <td>0.091870</td>\n",
       "      <td>0.804973</td>\n",
       "      <td>0.190387</td>\n",
       "      <td>-0.277410</td>\n",
       "      <td>-0.155875</td>\n",
       "      <td>-0.072523</td>\n",
       "      <td>0.053283</td>\n",
       "      <td>0.053725</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.072259</td>\n",
       "      <td>-0.084878</td>\n",
       "      <td>-0.051504</td>\n",
       "      <td>0.062293</td>\n",
       "      <td>0.175942</td>\n",
       "      <td>-0.066851</td>\n",
       "      <td>0.008647</td>\n",
       "      <td>0.021761</td>\n",
       "      <td>24.890000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>36950.000000</td>\n",
       "      <td>1.158111</td>\n",
       "      <td>0.740715</td>\n",
       "      <td>1.437952</td>\n",
       "      <td>1.071150</td>\n",
       "      <td>0.291005</td>\n",
       "      <td>0.486671</td>\n",
       "      <td>0.431341</td>\n",
       "      <td>0.322684</td>\n",
       "      <td>0.881834</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104925</td>\n",
       "      <td>0.302074</td>\n",
       "      <td>0.077032</td>\n",
       "      <td>0.401506</td>\n",
       "      <td>0.421921</td>\n",
       "      <td>0.303412</td>\n",
       "      <td>0.084708</td>\n",
       "      <td>0.076369</td>\n",
       "      <td>81.560000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>41599.000000</td>\n",
       "      <td>1.960497</td>\n",
       "      <td>17.930550</td>\n",
       "      <td>4.101716</td>\n",
       "      <td>16.491217</td>\n",
       "      <td>34.801666</td>\n",
       "      <td>22.529298</td>\n",
       "      <td>36.677268</td>\n",
       "      <td>20.007208</td>\n",
       "      <td>10.392889</td>\n",
       "      <td>...</td>\n",
       "      <td>22.614889</td>\n",
       "      <td>5.805795</td>\n",
       "      <td>17.297845</td>\n",
       "      <td>4.014444</td>\n",
       "      <td>5.525093</td>\n",
       "      <td>3.517346</td>\n",
       "      <td>11.135740</td>\n",
       "      <td>33.847808</td>\n",
       "      <td>7879.420000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time             V1             V2             V3  \\\n",
       "count  436630.000000  436630.000000  436630.000000  436630.000000   \n",
       "mean    26887.915901      -0.233305       0.031605       0.700511   \n",
       "std     12814.811924       1.881477       1.614104       1.524289   \n",
       "min         0.000000     -56.407510     -72.715728     -32.454198   \n",
       "25%     18716.000000      -0.980298      -0.539106       0.225524   \n",
       "50%     31883.000000      -0.244869       0.091870       0.804973   \n",
       "75%     36950.000000       1.158111       0.740715       1.437952   \n",
       "max     41599.000000       1.960497      17.930550       4.101716   \n",
       "\n",
       "                  V4             V5             V6             V7  \\\n",
       "count  436630.000000  436630.000000  436630.000000  436630.000000   \n",
       "mean        0.191717      -0.243616       0.099243      -0.117611   \n",
       "std         1.407336       1.409002       1.310496       1.272766   \n",
       "min        -5.172595     -42.147898     -26.160506     -26.548144   \n",
       "25%        -0.715683      -0.848293      -0.637899      -0.599202   \n",
       "50%         0.190387      -0.277410      -0.155875      -0.072523   \n",
       "75%         1.071150       0.291005       0.486671       0.431341   \n",
       "max        16.491217      34.801666      22.529298      36.677268   \n",
       "\n",
       "                  V8             V9  ...            V21            V22  \\\n",
       "count  436630.000000  436630.000000  ...  436630.000000  436630.000000   \n",
       "mean        0.051500       0.173597  ...      -0.026791      -0.110083   \n",
       "std         1.214445       1.226177  ...       0.739610       0.637123   \n",
       "min       -41.484823      -8.507059  ...     -20.262054      -8.593642   \n",
       "25%        -0.149296      -0.579461  ...      -0.233426      -0.530961   \n",
       "50%         0.053283       0.053725  ...      -0.072259      -0.084878   \n",
       "75%         0.322684       0.881834  ...       0.104925       0.302074   \n",
       "max        20.007208      10.392889  ...      22.614889       5.805795   \n",
       "\n",
       "                 V23            V24            V25            V26  \\\n",
       "count  436630.000000  436630.000000  436630.000000  436630.000000   \n",
       "mean       -0.039981       0.009708       0.136439       0.022624   \n",
       "std         0.568360       0.592318       0.437458       0.503347   \n",
       "min       -26.751119      -2.836627      -7.495741      -1.438650   \n",
       "25%        -0.179119      -0.322003      -0.128050      -0.329467   \n",
       "50%        -0.051504       0.062293       0.175942      -0.066851   \n",
       "75%         0.077032       0.401506       0.421921       0.303412   \n",
       "max        17.297845       4.014444       5.525093       3.517346   \n",
       "\n",
       "                 V27            V28         Amount          Class  \n",
       "count  436630.000000  436630.000000  436630.000000  436630.000000  \n",
       "mean        0.006871       0.005107      90.313927       0.003069  \n",
       "std         0.390441       0.342266     238.439495       0.055313  \n",
       "min        -8.567638      -9.617915       0.000000       0.000000  \n",
       "25%        -0.063373      -0.006856       7.570000       0.000000  \n",
       "50%         0.008647       0.021761      24.890000       0.000000  \n",
       "75%         0.084708       0.076369      81.560000       0.000000  \n",
       "max        11.135740      33.847808    7879.420000       1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_raw_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 436630 entries, 0 to 436629\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    436630 non-null  float64\n",
      " 1   V1      436630 non-null  float64\n",
      " 2   V2      436630 non-null  float64\n",
      " 3   V3      436630 non-null  float64\n",
      " 4   V4      436630 non-null  float64\n",
      " 5   V5      436630 non-null  float64\n",
      " 6   V6      436630 non-null  float64\n",
      " 7   V7      436630 non-null  float64\n",
      " 8   V8      436630 non-null  float64\n",
      " 9   V9      436630 non-null  float64\n",
      " 10  V10     436630 non-null  float64\n",
      " 11  V11     436630 non-null  float64\n",
      " 12  V12     436630 non-null  float64\n",
      " 13  V13     436630 non-null  float64\n",
      " 14  V14     436630 non-null  float64\n",
      " 15  V15     436630 non-null  float64\n",
      " 16  V16     436630 non-null  float64\n",
      " 17  V17     436630 non-null  float64\n",
      " 18  V18     436630 non-null  float64\n",
      " 19  V19     436630 non-null  float64\n",
      " 20  V20     436630 non-null  float64\n",
      " 21  V21     436630 non-null  float64\n",
      " 22  V22     436630 non-null  float64\n",
      " 23  V23     436630 non-null  float64\n",
      " 24  V24     436630 non-null  float64\n",
      " 25  V25     436630 non-null  float64\n",
      " 26  V26     436630 non-null  float64\n",
      " 27  V27     436630 non-null  float64\n",
      " 28  V28     436630 non-null  float64\n",
      " 29  Amount  436630 non-null  float64\n",
      " 30  Class   436630 non-null  float64\n",
      "dtypes: float64(31)\n",
      "memory usage: 106.6 MB\n"
     ]
    }
   ],
   "source": [
    "big_raw_data.info()   #shows no null values in any of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look like the np.percentile is not working\n",
    "np.percentile(raw_data.Class.values, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(436630, 31)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "2   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "3   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "4   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "2  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "3  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "4  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62    0.0  \n",
       "1 -0.189115  0.133558 -0.021053  149.62    0.0  \n",
       "2 -0.189115  0.133558 -0.021053  149.62    0.0  \n",
       "3 -0.189115  0.133558 -0.021053  149.62    0.0  \n",
       "4 -0.189115  0.133558 -0.021053  149.62    0.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "2 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "3 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "4 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "\n",
       "         V8        V9       V10  ...       V20       V21       V22       V23  \\\n",
       "0  0.098698  0.363787  0.090794  ...  0.251412 -0.018307  0.277838 -0.110474   \n",
       "1  0.098698  0.363787  0.090794  ...  0.251412 -0.018307  0.277838 -0.110474   \n",
       "2  0.098698  0.363787  0.090794  ...  0.251412 -0.018307  0.277838 -0.110474   \n",
       "3  0.098698  0.363787  0.090794  ...  0.251412 -0.018307  0.277838 -0.110474   \n",
       "4  0.098698  0.363787  0.090794  ...  0.251412 -0.018307  0.277838 -0.110474   \n",
       "\n",
       "        V24       V25       V26       V27       V28  Amount  \n",
       "0  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62  \n",
       "1  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62  \n",
       "2  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62  \n",
       "3  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62  \n",
       "4  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_raw_data.iloc[:, 1:30].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "1    0.0\n",
       "2    0.0\n",
       "3    0.0\n",
       "4    0.0\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_raw_data.iloc[:, 30].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"dataset_preprocessing\">\n",
    "    <h2>Dataset Preprocessing</h2>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this subsection you will prepare the data for training. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape= (436630, 29) y.shape= (436630,)\n"
     ]
    }
   ],
   "source": [
    "# data preprocessing such as scaling/normalization is typically useful for \n",
    "# linear models to accelerate the training convergence\n",
    "\n",
    "# standardize features by removing the mean and scaling to unit variance: to each value in a column you subtract the mean and divide by the sd of that column\n",
    "big_raw_data.iloc[:, 1:30] = StandardScaler().fit_transform(big_raw_data.iloc[:, 1:30])\n",
    "data_matrix = big_raw_data.values\n",
    "\n",
    "# X: feature matrix (for this analysis, we exclude the Time variable from the dataset)\n",
    "X = data_matrix[:, 1:30]\n",
    "\n",
    "# y: labels vector   \n",
    "y = data_matrix[:, 30]\n",
    "\n",
    "# data normalization   #in each of the columns the values will range between 0 and 1\n",
    "X = normalize(X, norm=\"l1\")\n",
    "\n",
    "# print the shape of the features matrix and the labels vector\n",
    "print('X.shape=', X.shape, 'y.shape=', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.598733</td>\n",
       "      <td>-0.064671</td>\n",
       "      <td>1.20439</td>\n",
       "      <td>0.84304</td>\n",
       "      <td>-0.067214</td>\n",
       "      <td>0.277105</td>\n",
       "      <td>0.280657</td>\n",
       "      <td>0.038863</td>\n",
       "      <td>0.155108</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011471</td>\n",
       "      <td>0.608863</td>\n",
       "      <td>-0.124029</td>\n",
       "      <td>0.096604</td>\n",
       "      <td>-0.018058</td>\n",
       "      <td>-0.420662</td>\n",
       "      <td>0.324474</td>\n",
       "      <td>-0.076432</td>\n",
       "      <td>0.248726</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.598733</td>\n",
       "      <td>-0.064671</td>\n",
       "      <td>1.20439</td>\n",
       "      <td>0.84304</td>\n",
       "      <td>-0.067214</td>\n",
       "      <td>0.277105</td>\n",
       "      <td>0.280657</td>\n",
       "      <td>0.038863</td>\n",
       "      <td>0.155108</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011471</td>\n",
       "      <td>0.608863</td>\n",
       "      <td>-0.124029</td>\n",
       "      <td>0.096604</td>\n",
       "      <td>-0.018058</td>\n",
       "      <td>-0.420662</td>\n",
       "      <td>0.324474</td>\n",
       "      <td>-0.076432</td>\n",
       "      <td>0.248726</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.598733</td>\n",
       "      <td>-0.064671</td>\n",
       "      <td>1.20439</td>\n",
       "      <td>0.84304</td>\n",
       "      <td>-0.067214</td>\n",
       "      <td>0.277105</td>\n",
       "      <td>0.280657</td>\n",
       "      <td>0.038863</td>\n",
       "      <td>0.155108</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011471</td>\n",
       "      <td>0.608863</td>\n",
       "      <td>-0.124029</td>\n",
       "      <td>0.096604</td>\n",
       "      <td>-0.018058</td>\n",
       "      <td>-0.420662</td>\n",
       "      <td>0.324474</td>\n",
       "      <td>-0.076432</td>\n",
       "      <td>0.248726</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.598733</td>\n",
       "      <td>-0.064671</td>\n",
       "      <td>1.20439</td>\n",
       "      <td>0.84304</td>\n",
       "      <td>-0.067214</td>\n",
       "      <td>0.277105</td>\n",
       "      <td>0.280657</td>\n",
       "      <td>0.038863</td>\n",
       "      <td>0.155108</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011471</td>\n",
       "      <td>0.608863</td>\n",
       "      <td>-0.124029</td>\n",
       "      <td>0.096604</td>\n",
       "      <td>-0.018058</td>\n",
       "      <td>-0.420662</td>\n",
       "      <td>0.324474</td>\n",
       "      <td>-0.076432</td>\n",
       "      <td>0.248726</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.598733</td>\n",
       "      <td>-0.064671</td>\n",
       "      <td>1.20439</td>\n",
       "      <td>0.84304</td>\n",
       "      <td>-0.067214</td>\n",
       "      <td>0.277105</td>\n",
       "      <td>0.280657</td>\n",
       "      <td>0.038863</td>\n",
       "      <td>0.155108</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011471</td>\n",
       "      <td>0.608863</td>\n",
       "      <td>-0.124029</td>\n",
       "      <td>0.096604</td>\n",
       "      <td>-0.018058</td>\n",
       "      <td>-0.420662</td>\n",
       "      <td>0.324474</td>\n",
       "      <td>-0.076432</td>\n",
       "      <td>0.248726</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2       V3       V4        V5        V6        V7  \\\n",
       "0   0.0 -0.598733 -0.064671  1.20439  0.84304 -0.067214  0.277105  0.280657   \n",
       "1   0.0 -0.598733 -0.064671  1.20439  0.84304 -0.067214  0.277105  0.280657   \n",
       "2   0.0 -0.598733 -0.064671  1.20439  0.84304 -0.067214  0.277105  0.280657   \n",
       "3   0.0 -0.598733 -0.064671  1.20439  0.84304 -0.067214  0.277105  0.280657   \n",
       "4   0.0 -0.598733 -0.064671  1.20439  0.84304 -0.067214  0.277105  0.280657   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.038863  0.155108  ...  0.011471  0.608863 -0.124029  0.096604 -0.018058   \n",
       "1  0.038863  0.155108  ...  0.011471  0.608863 -0.124029  0.096604 -0.018058   \n",
       "2  0.038863  0.155108  ...  0.011471  0.608863 -0.124029  0.096604 -0.018058   \n",
       "3  0.038863  0.155108  ...  0.011471  0.608863 -0.124029  0.096604 -0.018058   \n",
       "4  0.038863  0.155108  ...  0.011471  0.608863 -0.124029  0.096604 -0.018058   \n",
       "\n",
       "        V26       V27       V28    Amount  Class  \n",
       "0 -0.420662  0.324474 -0.076432  0.248726    0.0  \n",
       "1 -0.420662  0.324474 -0.076432  0.248726    0.0  \n",
       "2 -0.420662  0.324474 -0.076432  0.248726    0.0  \n",
       "3 -0.420662  0.324474 -0.076432  0.248726    0.0  \n",
       "4 -0.420662  0.324474 -0.076432  0.248726    0.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"dataset_split\">\n",
    "    <h2>Dataset Train/Test Split</h2>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the dataset is ready for building the classification models, you need to first divide the pre-processed dataset into a subset to be used for training the model (the train set) and a subset to be used for evaluating the quality of the model (the test set).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape= (305641, 29) Y_train.shape= (305641,)\n",
      "X_test.shape= (130989, 29) Y_test.shape= (130989,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)       \n",
    "print('X_train.shape=', X_train.shape, 'Y_train.shape=', y_train.shape)\n",
    "print('X_test.shape=', X_test.shape, 'Y_test.shape=', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"dt_sklearn\">\n",
    "    <h2>Build a Decision Tree Classifier model with Scikit-Learn</h2>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Scikit-Learn] Training time (s):  2.80876\n"
     ]
    }
   ],
   "source": [
    "# compute the sample weights to be used as input to the train routine so that \n",
    "# it takes into account the class imbalance present in this dataset\n",
    "w_train = compute_sample_weight('balanced', y_train)\n",
    "\n",
    "# import the Decision Tree Classifier Model from scikit-learn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# for reproducible output across multiple function calls, set random_state to a given integer value\n",
    "sklearn_dt = DecisionTreeClassifier(max_depth=4, random_state=35)\n",
    "\n",
    "# train a Decision Tree Classifier using scikit-learn\n",
    "t0 = time.time()\n",
    "sklearn_dt.fit(X_train, y_train, sample_weight=w_train)\n",
    "sklearn_time = time.time()-t0\n",
    "print(\"[Scikit-Learn] Training time (s):  {0:.5f}\".format(sklearn_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"dt_snapml\">\n",
    "    <h2>Build a Decision Tree Classifier model with Snap ML</h2>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Snap ML] Training time (s):  1.19201\n"
     ]
    }
   ],
   "source": [
    "# if not already computed, \n",
    "# compute the sample weights to be used as input to the train routine so that \n",
    "# it takes into account the class imbalance present in this dataset\n",
    "# w_train = compute_sample_weight('balanced', y_train)\n",
    "\n",
    "# import the Decision Tree Classifier Model from Snap ML\n",
    "from snapml import DecisionTreeClassifier\n",
    "\n",
    "# Snap ML offers multi-threaded CPU/GPU training of decision trees, unlike scikit-learn\n",
    "# to use the GPU, set the use_gpu parameter to True\n",
    "# snapml_dt = DecisionTreeClassifier(max_depth=4, random_state=45, use_gpu=True)\n",
    "\n",
    "# to set the number of CPU threads used at training time, set the n_jobs parameter\n",
    "# for reproducible output across multiple function calls, set random_state to a given integer value\n",
    "snapml_dt = DecisionTreeClassifier(max_depth=4, random_state=45, n_jobs=4)\n",
    "\n",
    "# train a Decision Tree Classifier model using Snap ML\n",
    "t0 = time.time()\n",
    "snapml_dt.fit(X_train, y_train, sample_weight=w_train)\n",
    "snapml_time = time.time()-t0\n",
    "print(\"[Snap ML] Training time (s):  {0:.5f}\".format(snapml_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"dt_sklearn_snapml\">\n",
    "    <h2>Evaluate the Scikit-Learn and Snap ML Decision Tree Classifier Models</h2>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Decision Tree Classifier] Snap ML vs. Scikit-Learn speedup : 2.36x \n",
      "[Scikit-Learn] ROC-AUC score : 0.986\n",
      "[Snap ML] ROC-AUC score : 0.986\n"
     ]
    }
   ],
   "source": [
    "# Snap ML vs Scikit-Learn training speedup\n",
    "training_speedup = sklearn_time/snapml_time\n",
    "print('[Decision Tree Classifier] Snap ML vs. Scikit-Learn speedup : {0:.2f}x '.format(training_speedup))\n",
    "\n",
    "# run inference and compute the probabilities of the test samples \n",
    "# to belong to the class of fraudulent transactions\n",
    "sklearn_pred = sklearn_dt.predict_proba(X_test)[:,1]\n",
    "\n",
    "# evaluate the Compute Area Under the Receiver Operating Characteristic \n",
    "# Curve (ROC-AUC) score from the predictions\n",
    "sklearn_roc_auc = roc_auc_score(y_test, sklearn_pred)\n",
    "print('[Scikit-Learn] ROC-AUC score : {0:.3f}'.format(sklearn_roc_auc))\n",
    "\n",
    "# run inference and compute the probabilities of the test samples\n",
    "# to belong to the class of fraudulent transactions\n",
    "snapml_pred = snapml_dt.predict_proba(X_test)[:,1]\n",
    "\n",
    "# evaluate the Compute Area Under the Receiver Operating Characteristic\n",
    "# Curve (ROC-AUC) score from the prediction scores\n",
    "snapml_roc_auc = roc_auc_score(y_test, snapml_pred)   \n",
    "print('[Snap ML] ROC-AUC score : {0:.3f}'.format(snapml_roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above both decision tree models provide the same score on the test dataset. However Snap ML runs the training routine 12x faster than Scikit-Learn. This is one of the advantages of using Snap ML: acceleration of training of classical machine learning models, such as linear and tree-based models. For more Snap ML examples, please visit [snapml-examples](https://ibm.biz/BdPfxP?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork1047-2022-01-01).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"svm_sklearn\">\n",
    "    <h2>Build a Support Vector Machine model with Scikit-Learn</h2>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Scikit-Learn] Training time (s):  3.06\n"
     ]
    }
   ],
   "source": [
    "# import the linear Support Vector Machine (SVM) model from Scikit-Learn\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# instatiate a scikit-learn SVM model\n",
    "# to indicate the class imbalance at fit time, set class_weight='balanced'\n",
    "# for reproducible output across multiple function calls, set random_state to a given integer value\n",
    "sklearn_svm = LinearSVC(class_weight='balanced', random_state=31, loss=\"hinge\", fit_intercept=False)\n",
    "\n",
    "# train a linear Support Vector Machine model using Scikit-Learn\n",
    "t0 = time.time()\n",
    "sklearn_svm.fit(X_train, y_train)\n",
    "sklearn_time = time.time() - t0\n",
    "print(\"[Scikit-Learn] Training time (s):  {0:.2f}\".format(sklearn_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"svm_snap\">\n",
    "    <h2>Build a Support Vector Machine model with Snap ML</h2>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Snap ML] Training time (s):  5.55\n"
     ]
    }
   ],
   "source": [
    "# import the Support Vector Machine model (SVM) from Snap ML\n",
    "from snapml import SupportVectorMachine\n",
    "\n",
    "# in contrast to scikit-learn's LinearSVC, Snap ML offers multi-threaded CPU/GPU training of SVMs\n",
    "# to use the GPU, set the use_gpu parameter to True\n",
    "# snapml_svm = SupportVectorMachine(class_weight='balanced', random_state=25, use_gpu=True, fit_intercept=False)\n",
    "\n",
    "# to set the number of threads used at training time, one needs to set the n_jobs parameter\n",
    "snapml_svm = SupportVectorMachine(class_weight='balanced', random_state=25, n_jobs=4, fit_intercept=False)\n",
    "# print(snapml_svm.get_params())\n",
    "\n",
    "# train an SVM model using Snap ML\n",
    "t0 = time.time()\n",
    "model = snapml_svm.fit(X_train, y_train)\n",
    "snapml_time = time.time() - t0\n",
    "print(\"[Snap ML] Training time (s):  {0:.2f}\".format(snapml_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"svm_sklearn_snap\">\n",
    "    <h2>Evaluate the Scikit-Learn and Snap ML Support Vector Machine Models</h2>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Support Vector Machine] Snap ML vs. Scikit-Learn training speedup : 0.55x \n",
      "[Scikit-Learn] ROC-AUC score:   0.992\n",
      "[Snap ML] ROC-AUC score:   0.992\n"
     ]
    }
   ],
   "source": [
    "# compute the Snap ML vs Scikit-Learn training speedup\n",
    "training_speedup = sklearn_time/snapml_time\n",
    "print('[Support Vector Machine] Snap ML vs. Scikit-Learn training speedup : {0:.2f}x '.format(training_speedup))\n",
    "\n",
    "# run inference using the Scikit-Learn model\n",
    "# get the confidence scores for the test samples\n",
    "sklearn_pred = sklearn_svm.decision_function(X_test)\n",
    "\n",
    "# evaluate accuracy on test set\n",
    "acc_sklearn  = roc_auc_score(y_test, sklearn_pred)\n",
    "print(\"[Scikit-Learn] ROC-AUC score:   {0:.3f}\".format(acc_sklearn))\n",
    "\n",
    "# run inference using the Snap ML model\n",
    "# get the confidence scores for the test samples\n",
    "snapml_pred = snapml_svm.decision_function(X_test)\n",
    "\n",
    "# evaluate accuracy on test set\n",
    "acc_snapml  = roc_auc_score(y_test, snapml_pred)\n",
    "print(\"[Snap ML] ROC-AUC score:   {0:.3f}\".format(acc_snapml))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above both SVM models provide the same score on the test dataset. However, as in the case of decision trees, Snap ML runs the training routine faster than Scikit-Learn. For more Snap ML examples, please visit [snapml-examples](https://ibm.biz/BdPfxP?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork1047-2022-01-01). Moreover, as shown above, not only is Snap ML seemlessly accelerating scikit-learn applications, but the library's Python API is also compatible with scikit-learn metrics and data preprocessors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section you will evaluate the quality of the SVM models trained above using the hinge loss metric (https://scikit-learn.org/stable/modules/generated/sklearn.metrics.hinge_loss.html). Run inference on the test set using both Scikit-Learn and Snap ML models. Compute the hinge loss metric for both sets of predictions. Print the hinge losses of Scikit-Learn and Snap ML.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Snap ML] Hinge loss:   0.160\n",
      "[Scikit-Learn] Hinge loss:   0.169\n"
     ]
    }
   ],
   "source": [
    "# get the confidence scores for the test samples\n",
    "sklearn_pred = sklearn_svm.decision_function(X_test)\n",
    "snapml_pred  = snapml_svm.decision_function(X_test)\n",
    "\n",
    "# import the hinge_loss metric from scikit-learn\n",
    "from sklearn.metrics import hinge_loss\n",
    "\n",
    "# evaluate the hinge loss from the predictions\n",
    "loss_snapml = hinge_loss(y_test, snapml_pred)\n",
    "print(\"[Snap ML] Hinge loss:   {0:.3f}\".format(loss_snapml))\n",
    "\n",
    "# evaluate the hinge loss metric from the predictions\n",
    "loss_sklearn = hinge_loss(y_test, sklearn_pred)\n",
    "print(\"[Scikit-Learn] Hinge loss:   {0:.3f}\".format(loss_sklearn))\n",
    "\n",
    "# the two models should give the same Hinge loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Andreea Anghel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Contributors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joseph Santarcangelo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n",
    "|---|---|---|---|\n",
    "| 2021-08-31  | 0.1  | AAN  |  Created Lab Content |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Copyright &copy; 2021 IBM Corporation. This notebook and its source code are released under the terms of the [MIT License](https://cognitiveclass.ai/mit-license/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork1047-2022-01-01).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
